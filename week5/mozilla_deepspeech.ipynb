{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mozilla DeepSpeech\n",
    "DeepSpeech is an open source Speech-To-Text engine, using a model trained by machine learning techniques based on Baidu's [Deep Speech research paper](https://arxiv.org/abs/1412.5567). Project DeepSpeech uses Google's TensorFlow to make the implementation easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install DeepSpeech:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\r\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\r\n",
      "Requirement already satisfied: deepspeech-gpu in /home/rtwomey/.local/lib/python3.7/site-packages (0.5.1)\r\n",
      "Requirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from deepspeech-gpu) (1.16.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install deepspeech-gpu --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download pretrained models: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   620    0   620    0     0   2238      0 --:--:-- --:--:-- --:--:--  2238\n",
      "100 1828M  100 1828M    0     0  43.1M      0  0:00:42  0:00:42 --:--:-- 44.8M\n",
      "./._deepspeech-0.5.1-models\n",
      "deepspeech-0.5.1-models/\n",
      "deepspeech-0.5.1-models/._lm.binary\n",
      "deepspeech-0.5.1-models/lm.binary\n",
      "deepspeech-0.5.1-models/._output_graph.pbmm\n",
      "deepspeech-0.5.1-models/output_graph.pbmm\n",
      "deepspeech-0.5.1-models/._output_graph.pb\n",
      "deepspeech-0.5.1-models/output_graph.pb\n",
      "deepspeech-0.5.1-models/._trie\n",
      "deepspeech-0.5.1-models/trie\n",
      "deepspeech-0.5.1-models/._output_graph.tflite\n",
      "deepspeech-0.5.1-models/output_graph.tflite\n",
      "deepspeech-0.5.1-models/._alphabet.txt\n",
      "deepspeech-0.5.1-models/alphabet.txt\n"
     ]
    }
   ],
   "source": [
    "!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.5.1/deepspeech-0.5.1-models.tar.gz\n",
    "!tar xvf deepspeech-0.5.1-models.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download example audio files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   608    0   608    0     0   2118      0 --:--:-- --:--:-- --:--:--  2118\n",
      "100  192k  100  192k    0     0   237k      0 --:--:-- --:--:-- --:--:--  237k\n",
      "audio/\n",
      "audio/2830-3980-0043.wav\n",
      "audio/Attribution.txt\n",
      "audio/4507-16021-0012.wav\n",
      "audio/8455-210777-0068.wav\n",
      "audio/License.txt\n"
     ]
    }
   ],
   "source": [
    "# Download example audio files\n",
    "!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.5.1/audio-0.5.1.tar.gz\n",
    "!tar xvf audio-0.5.1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model\n",
    "\n",
    "Open the terminal (__New->Terminal__), switch to this directory.\n",
    "\n",
    "Run this command to identify speech in a sample audio file: \n",
    "\n",
    "```\n",
    "deepspeech --model deepspeech-0.5.1-models/output_graph.pbmm --alphabet deepspeech-0.5.1-models/alphabet.txt --lm deepspeech-0.5.1-models/lm.binary --trie deepspeech-0.5.1-models/trie --audio audio/2830-3980-0043.wav```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example output: \n",
    "\n",
    "```\n",
    "deepspeech --model deepspeech-0.5.1-models/output_graph.pbmm --alphabet deepspeech-0.5.1-models/alphabet.txt --lm deepspeech-0.5.1-models/lm.binary --trie deepspeech-0.5.1-models/trie --audio audio/2830-3980-0043.wav\n",
    "Loading model from file deepspeech-0.5.1-models/output_graph.pbmm\n",
    "TensorFlow: v1.13.1-10-g3e0cc53\n",
    "DeepSpeech: v0.5.1-0-g4b29b78\n",
    "2019-10-30 04:39:32.201283: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
    "2019-10-30 04:39:32.442607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties:\n",
    "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
    "pciBusID: 0000:86:00.0\n",
    "totalMemory: 10.92GiB freeMemory: 10.61GiB\n",
    "2019-10-30 04:39:32.442692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
    "2019-10-30 04:40:59.290914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
    "2019-10-30 04:40:59.290966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0\n",
    "2019-10-30 04:40:59.290978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N\n",
    "2019-10-30 04:40:59.291614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10268 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:86:00.0, compute capability: 6.1)\n",
    "2019-10-30 04:40:59.306045: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"UnwrapDatasetVariant\" device_type: \"CPU\"') for unknown op: UnwrapDatasetVariant\n",
    "2019-10-30 04:40:59.306088: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"WrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"') for unknown op: WrapDatasetVariant\n",
    "2019-10-30 04:40:59.306104: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"WrapDatasetVariant\" device_type: \"CPU\"') forunknown op: WrapDatasetVariant\n",
    "2019-10-30 04:40:59.306440: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"UnwrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"') for unknown op: UnwrapDatasetVariant\n",
    "Loaded model in 87.1s.\n",
    "Loading language model from files deepspeech-0.5.1-models/lm.binary deepspeech-0.5.1-models/trie\n",
    "Loaded language model in 0.423s.\n",
    "Running inference.\n",
    "2019-10-30 04:40:59.938355: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
    "experience proof this\n",
    "Inference took 1.050s for 1.975s audio file.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activities\n",
    "- Upload your own audio files to recognize speech.\n",
    "  - what audio file format is necessary for input? (16bit wave signed LE)\n",
    "  - you will likely need to downsample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "- More information on the project webpage [https://github.com/mozilla/DeepSpeech](https://github.com/mozilla/DeepSpeech)\n",
    "- See [client.py](https://github.com/mozilla/DeepSpeech/blob/master/native_client/python/client.py) for mor information on how to use deepspeech programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
