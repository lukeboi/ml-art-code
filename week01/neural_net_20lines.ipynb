{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a 2-Layer Neural Network in 20 lines\n",
    "\n",
    "From Stanford CSE231n http://cs231n.stanford.edu/slides/2019/cs231n_2019_lecture04.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 27696.504071495514\n",
      "20 7311.98259504007\n",
      "40 5131.440921617048\n",
      "60 3808.3853770229703\n",
      "80 2993.8675356111307\n",
      "100 2419.9515764763573\n",
      "120 1977.3128204618906\n",
      "140 1658.022621978637\n",
      "160 1395.096756635477\n",
      "180 1192.3690524801127\n",
      "200 1033.7847695123228\n",
      "220 900.5509001491398\n",
      "240 791.7033243632392\n",
      "260 698.1698552425471\n",
      "280 621.3242404632076\n",
      "300 556.5602886901277\n",
      "320 497.39499468358395\n",
      "340 442.12016321269823\n",
      "360 398.89441083943507\n",
      "380 361.21149466523775\n",
      "400 327.9953999065358\n",
      "420 298.464374014159\n",
      "440 271.96650886692487\n",
      "460 248.39343487916832\n",
      "480 227.53008790746705\n",
      "500 208.71135818066156\n",
      "520 190.78145558638818\n",
      "540 175.61489714600697\n",
      "560 161.88831240230985\n",
      "580 149.5009484456477\n",
      "600 138.74235927138372\n",
      "620 129.16024496078956\n",
      "640 120.53096343311523\n",
      "660 112.71610121412458\n",
      "680 105.60132803790697\n",
      "700 99.09274476473195\n",
      "720 93.11007057554247\n",
      "740 87.5851266807158\n",
      "760 82.46105735932063\n",
      "780 77.68713685008882\n",
      "800 73.22021575470109\n",
      "820 69.04581756913325\n",
      "840 65.17386521847197\n",
      "860 61.59569646234979\n",
      "880 58.2826072052131\n",
      "900 55.20631324816351\n",
      "920 52.34278084518919\n",
      "940 49.67212205337019\n",
      "960 47.17819836034614\n",
      "980 44.84657815683476\n",
      "1000 42.66331871243856\n",
      "1020 40.6150571004327\n",
      "1040 38.6894276717758\n",
      "1060 36.87532110327045\n",
      "1080 35.16301478728897\n",
      "1100 33.54428092235928\n",
      "1120 32.01249011551367\n",
      "1140 30.56262222546818\n",
      "1160 29.191015361551358\n",
      "1180 27.89470618316822\n",
      "1200 26.67055559819845\n",
      "1220 25.514766434453925\n",
      "1240 24.42303880204316\n",
      "1260 23.390963040446813\n",
      "1280 22.414309683132707\n",
      "1300 21.48916855462745\n",
      "1320 20.61198055487924\n",
      "1340 19.779512127408353\n",
      "1360 18.988811064826123\n",
      "1380 18.23716357525428\n",
      "1400 17.52205891866893\n",
      "1420 16.841162024583376\n",
      "1440 16.192292788374452\n",
      "1460 15.573410424549682\n",
      "1480 14.98260139648585\n",
      "1500 14.4180699243039\n",
      "1520 13.878130838879404\n",
      "1540 13.361205431114767\n",
      "1560 12.865821710090742\n",
      "1580 12.3906208156332\n",
      "1600 11.934370676970994\n",
      "1620 11.495985510660024\n",
      "1640 11.074544790597448\n",
      "1660 10.669299304506916\n",
      "1680 10.279650467612544\n",
      "1700 9.905100064707618\n",
      "1720 9.545190102983298\n",
      "1740 9.199467157598733\n",
      "1760 8.867491380051021\n",
      "1780 8.548876026347122\n",
      "1800 8.243320252832113\n",
      "1820 7.95060041385649\n",
      "1840 7.670507579611396\n",
      "1860 7.402755497957568\n",
      "1880 7.146913751733502\n",
      "1900 6.902409314075424\n",
      "1920 6.668587890248909\n",
      "1940 6.444788493375746\n",
      "1960 6.230393427649989\n",
      "1980 6.024846405869955\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.random import randn\n",
    "\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10 \n",
    "x, y = randn(N, D_in), randn(N, D_out)\n",
    "w1, w2 = randn(D_in, H), randn(H, D_out)\n",
    "\n",
    "for t in range(2000):\n",
    "    h = 1 / (1 + np.exp(-x.dot(w1))) # hidden layer activations\n",
    "    y_pred = h.dot(w2) # output activations\n",
    "    loss = np.square(y_pred - y).sum() # squared error\n",
    "    if t % 20 == 0:\n",
    "        print(t, loss)\n",
    "    \n",
    "    grad_y_pred = 2.0 * (y_pred - y) # derivative of 1/(y_p-y)^2\n",
    "    grad_w2 = h.T.dot(grad_y_pred)\n",
    "    grad_h = grad_y_pred.dot(w2.T)\n",
    "    grad_w1 = x.T.dot(grad_h * h * (1 - h))\n",
    "    \n",
    "    w1 -= 1e-4 * grad_w1 # 1e-04 is learning rate (0.0001)\n",
    "    w2 -= 1e-4 * grad_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
