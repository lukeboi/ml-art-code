{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a 2-Layer Neural Network in 20 lines\n",
    "\n",
    "From Stanford CSE231n http://cs231n.stanford.edu/slides/2019/cs231n_2019_lecture04.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 27096.870576723348\n",
      "20 6207.938735359612\n",
      "40 4404.841816872335\n",
      "60 3437.623687653429\n",
      "80 2735.6874698538845\n",
      "100 2220.824313326603\n",
      "120 1848.2517550664088\n",
      "140 1558.2191158536107\n",
      "160 1327.3812229748928\n",
      "180 1143.61416291434\n",
      "200 996.9783587102884\n",
      "220 865.1482403972238\n",
      "240 760.0393305977881\n",
      "260 676.1790058560051\n",
      "280 607.8268188147501\n",
      "300 550.7849094721824\n",
      "320 501.7172789399401\n",
      "340 458.77469880947314\n",
      "360 420.63333146015947\n",
      "380 386.38310064197213\n",
      "400 355.9496112307752\n",
      "420 328.7904376195774\n",
      "440 303.9467507424172\n",
      "460 281.2759995754902\n",
      "480 260.69980635430363\n",
      "500 242.14653837459815\n",
      "520 225.12178949716844\n",
      "540 208.68523947168566\n",
      "560 193.44524310305627\n",
      "580 180.58873516081982\n",
      "600 169.0912548343686\n",
      "620 158.59333854276832\n",
      "640 148.9796557946101\n",
      "660 140.1499363777605\n",
      "680 132.02174163406252\n",
      "700 124.52685252696594\n",
      "720 117.59236548997956\n",
      "740 111.14355916292374\n",
      "760 105.11602684881652\n",
      "780 99.44457491237092\n",
      "800 94.04093903777775\n",
      "820 88.84459178800392\n",
      "840 83.98257400634952\n",
      "860 79.49837414246137\n",
      "880 75.30694097074469\n",
      "900 71.35831695061614\n",
      "920 67.67334336419233\n",
      "940 64.27813731094041\n",
      "960 61.12798886549041\n",
      "980 58.17630766819393\n",
      "1000 55.3950666383428\n",
      "1020 52.76312890705789\n",
      "1040 50.26051038901528\n",
      "1060 47.87051159239593\n",
      "1080 45.593741160173465\n",
      "1100 43.45332353557661\n",
      "1120 41.45416915319054\n",
      "1140 39.57806847133135\n",
      "1160 37.81091499033709\n",
      "1180 36.14472814978345\n",
      "1200 34.5724340952698\n",
      "1220 33.08608571811625\n",
      "1240 31.677949356634546\n",
      "1260 30.341313293647392\n",
      "1280 29.07043695382611\n",
      "1300 27.860353280190225\n",
      "1320 26.706806881276698\n",
      "1340 25.606297500460713\n",
      "1360 24.556130817354394\n",
      "1380 23.55433342109939\n",
      "1400 22.599296420247033\n",
      "1420 21.68922844609087\n",
      "1440 20.82179530310558\n",
      "1460 19.994215243829526\n",
      "1480 19.203617535089467\n",
      "1500 18.44732170491848\n",
      "1520 17.722931071261925\n",
      "1540 17.02832325500874\n",
      "1560 16.361637146446444\n",
      "1580 15.721322759844325\n",
      "1600 15.10629770355025\n",
      "1620 14.516183823755668\n",
      "1640 13.951379483138824\n",
      "1660 13.412548052236335\n",
      "1680 12.899650561588778\n",
      "1700 12.411533947336142\n",
      "1720 11.946456623505084\n",
      "1740 11.502715603352136\n",
      "1760 11.07885010014921\n",
      "1780 10.67360100784587\n",
      "1800 10.28584688479489\n",
      "1820 9.914570026416062\n",
      "1840 9.558841086676955\n",
      "1860 9.217809980273557\n",
      "1880 8.89069862089486\n",
      "1900 8.576794408004979\n",
      "1920 8.275443999217885\n",
      "1940 7.9860469894987745\n",
      "1960 7.708049355297343\n",
      "1980 7.440936870148466\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.random import randn\n",
    "\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10 \n",
    "x, y = randn(N, D_in), randn(N, D_out)\n",
    "w1, w2 = randn(D_in, H), randn(H, D_out)\n",
    "\n",
    "for t in range(2000):\n",
    "    h = 1 / (1 + np.exp(-x.dot(w1))) # hidden layer activations\n",
    "    y_pred = h.dot(w2) # output activations\n",
    "    loss = np.square(y_pred - y).sum() # squared error\n",
    "    if t % 20 == 0:\n",
    "        print(t, loss)\n",
    "    \n",
    "    grad_y_pred = 2.0 * (y_pred - y) # derivative of 1/(y_p-y)^2\n",
    "    grad_w2 = h.T.dot(grad_y_pred)\n",
    "    grad_h = grad_y_pred.dot(w2.T)\n",
    "    grad_w1 = x.T.dot(grad_h * h * (1 - h))\n",
    "    \n",
    "    w1 -= 1e-4 * grad_w1 # 1e-04 is learning rate (0.0001)\n",
    "    w2 -= 1e-4 * grad_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
