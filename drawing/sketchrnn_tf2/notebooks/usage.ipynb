{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SketchRNN-TF2\n",
    "\n",
    "[SketchRNN-TF2](https://github.com/stwind/SketchRNN_tf2) implemented by Zihou Ng (stwind)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup\n",
    "\n",
    "Run the following cells one time to install the necessary packages for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install tqdm\n",
    "%pip install seaborn\n",
    "%pip install ipywidgets widgetsnbextension pandas-profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change to root directory of this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "install the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python setup.py install --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Start the session\n",
    "\n",
    "This is where you can start once you have done the initial install. You may need to restart the notebook for the new modules to be available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from IPython.display import HTML\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.patches import Rectangle, PathPatch\n",
    "from tensorflow import keras as K\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sketchrnn import models, dataset, utils\n",
    "\n",
    "sns.set('notebook', 'whitegrid', rc=utils.mpl_rc())\n",
    "\n",
    "# print some tensorflow version information\n",
    "print(\"tf: {}\".format(tf.version.VERSION))\n",
    "print(\"tf.keras: {}\".format(K.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "switch back to the main notebooks folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose one of the 345 categories in the [QuickDraw dataset](https://github.com/googlecreativelab/quickdraw-dataset/blob/master/categories.txt). We'll use \"rabbit\" below, but I encourage you to try your own. Notice how large the downloaded file is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_class = 'rabbit'\n",
    "\n",
    "utils.download_dataset('rabbit', '../data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".npz is a numpy (python) zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('../data/{}.npz'.format(data_class),encoding='latin1',allow_pickle=True)\n",
    "\n",
    "data_train = [dataset.cleanup(d) for d in data['train']]\n",
    "data_valid = [dataset.cleanup(d) for d in data['valid']]\n",
    "data_test = [dataset.cleanup(d) for d in data['test']]\n",
    "\n",
    "max_seq_len = max(map(len, np.concatenate([data_train, data_valid, data_test])))\n",
    "scale_factor = dataset.calc_scale_factor(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random samples from the raw test set. Each of these was drawn by a human, somewhere/when."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = [4, 10]\n",
    "\n",
    "fig, ax = plt.subplots(n[0],n[1],figsize=(12, 5))\n",
    "\n",
    "perm = np.random.permutation(range(len(data_test)))[:n[0]*n[1]]\n",
    "\n",
    "for i, idx in enumerate(perm):\n",
    "    x, y = i // n[1], i % n[1]\n",
    "    utils.plot_strokes(ax[x][y], data_train[idx])\n",
    "    ax[x][y].set(xlabel=idx)\n",
    "    \n",
    "utils.plt_show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some data cleaning for later use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = np.array([dataset.pad(dataset.normalize(d, scale_factor), max_seq_len) for d in data_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calc some stats about how many points and penstrokes exist in each image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = np.argmax(ds_test[:,:,4]==1,-1)\n",
    "n_strokes = ds_test[:,:,3].sum(1)\n",
    "\n",
    "pmin, pmax = np.percentile(n_points,[1,99])\n",
    "smin, smax = np.percentile(n_strokes,[1,99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12,4))\n",
    "\n",
    "ax[0].hist(n_points[(pmin < n_points) & (n_points < pmax)], 20, alpha=0.8)\n",
    "ax[0].set(xlabel=\"points\", \n",
    "          title=\"Distribution by number of points\")\n",
    "\n",
    "ax[1].hist(n_strokes[(smin < n_strokes) & (n_strokes < smax)], 10, alpha=0.8)\n",
    "ax[1].set(xlabel=\"strokes\", \n",
    "          title=\"Distribution by number of strokes\")\n",
    "\n",
    "utils.plt_show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove the ones that have invalide number of points or strokes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter invalid samples\n",
    "ds_test = ds_test[n_points > 0]\n",
    "n_strokes = n_strokes[n_points > 0]\n",
    "n_points = n_points[n_points > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load The Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set the [hyperparameters](https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)) for the SketchRNN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps = {\n",
    "    \"max_seq_len\": max_seq_len,\n",
    "    'batch_size': 100,\n",
    "    \"num_batches\": math.ceil(len(data_train) / 100),\n",
    "    \"epochs\": 1,\n",
    "    \"recurrent_dropout_prob\": 0.1,\n",
    "    \"enc_rnn_size\": 256,\n",
    "    \"dec_rnn_size\": 512,\n",
    "    \"z_size\": 128,\n",
    "    \"num_mixture\": 20,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"min_learning_rate\": 0.00001,\n",
    "    \"decay_rate\": 0.9999,\n",
    "    \"grad_clip\": 1.0,\n",
    "    'kl_tolerance': 0.2,\n",
    "    'kl_decay_rate': 0.99995,\n",
    "    \"kl_weight\": 0.5,\n",
    "    'kl_weight_start': 0.01,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model and trained weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sketchrnn = models.SketchRNN(hps)\n",
    "sketchrnn.models['full'].summary()\n",
    "\n",
    "initial_epoch, initial_loss = 100, 0.06\n",
    "checkpoint = os.path.join('../models/', 'sketch_rnn_{}_weights.{:02d}_{:.2f}.hdf5').format(data_class, initial_epoch, initial_loss)\n",
    "sketchrnn.load_weights(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a random sample from the latent space. Previously we grabbed an image from the dataset (so made by a human). Here we are generating an image using the trained model. Rerun this next cell to see new images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3, 3))\n",
    "\n",
    "strokes = sketchrnn.sample(temperature=0.1)\n",
    "utils.plot_strokes(ax, utils.to_normal_strokes(strokes))\n",
    "\n",
    "utils.plt_show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate some more random samples from the latent space (a grid of images):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = [5, 10]\n",
    "temp = 0.3\n",
    "\n",
    "fig, ax = plt.subplots(n[0],n[1],figsize=(12, 5))\n",
    "\n",
    "for i in trange(n[0] * n[1]):\n",
    "    strokes = sketchrnn.sample(temperature=temp)\n",
    "    utils.plot_strokes(ax[i // n[1]][i % n[1]], utils.to_normal_strokes(strokes))\n",
    "    \n",
    "fig.suptitle(\"Random Samples From Latent Space (t={})\".format(temp))\n",
    "\n",
    "utils.plt_show(rect=[0, 0, 1, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate some new ones at various temperatures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 5))\n",
    "\n",
    "n = [5,11]\n",
    "\n",
    "with tqdm(total=n[0]*n[1]) as pbar:\n",
    "    for i in range(n[0]):\n",
    "        z = np.random.randn(1, hps['z_size']).astype(np.float32)\n",
    "\n",
    "        for j in range(n[1]):\n",
    "            ax = plt.subplot(n[0], n[1], i * n[1] + j + 1)\n",
    "            if j == 0:\n",
    "                strokes = sketchrnn.sample(z=z,greedy=True)\n",
    "            else:\n",
    "                strokes = sketchrnn.sample(z=z,temperature=j*0.1)\n",
    "            utils.plot_strokes(ax, utils.to_normal_strokes(strokes))\n",
    "            ax.set(xlabel='greedy' if j == 0 else 't={:.1f}'.format(j*0.1))\n",
    "\n",
    "            pbar.update(1)\n",
    "            \n",
    "fig.suptitle(\"Varying temperature\")\n",
    "\n",
    "utils.plt_show(rect=[0, 0, 1, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can see how the model encodes/decodes samples with different temperatures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 5))\n",
    "\n",
    "n = 5\n",
    "\n",
    "indices = np.random.permutation(range(len(ds_test)))[:n]\n",
    "\n",
    "with tqdm(total=n*11) as pbar:\n",
    "    for i in range(n):\n",
    "        idx = indices[i]\n",
    "\n",
    "        d = np.expand_dims(ds_test[idx],0)\n",
    "        z = sketchrnn.models['encoder'].predict(d[:,1:])[0]\n",
    "\n",
    "        ax = plt.subplot(n, 11, i * 11 + 1)\n",
    "        utils.plot_strokes(ax, utils.to_normal_strokes(d[0]))\n",
    "        ax.set(xlabel=idx)\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "        for j in range(1,11):\n",
    "            strokes = sketchrnn.sample(z=z, temperature=j*0.1)\n",
    "\n",
    "            ax = plt.subplot(n, 11, i * 11 + j + 1)\n",
    "            utils.plot_strokes(ax, utils.to_normal_strokes(strokes))\n",
    "            ax.set(xlabel='t={:.1f}'.format(j*0.1))\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "utils.plt_show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to interpolation between samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "\n",
    "indices = np.random.permutation(range(len(ds_test)))[:n * 2]\n",
    "\n",
    "fig, ax = plt.subplots(n, 13, figsize=(12, 5))\n",
    "\n",
    "with tqdm(total=n*11) as pbar:\n",
    "    for i in range(n):\n",
    "        idx1, idx2 = indices[i*2:i*2+2]\n",
    "\n",
    "        d1, d2 = ds_test[idx1], ds_test[idx2]\n",
    "        z1 = sketchrnn.models['encoder'].predict(d1[np.newaxis,1:])[0].squeeze()\n",
    "        z2 = sketchrnn.models['encoder'].predict(d2[np.newaxis,1:])[0].squeeze()\n",
    "\n",
    "        utils.plot_strokes(ax[i][0], utils.to_normal_strokes(d1))\n",
    "        ax[i][0].set(xlabel=idx1)\n",
    "\n",
    "        for j in range(11):\n",
    "            z = np.expand_dims(utils.slerp(z1,z2,j*0.1),0)\n",
    "            strokes = sketchrnn.sample(z=z, greedy=True)\n",
    "            utils.plot_strokes(ax[i][j+1], utils.to_normal_strokes(strokes))\n",
    "            ax[i][j+1].set(xlabel='i={:.1f}'.format(j*0.1))\n",
    "            \n",
    "            pbar.update(1)\n",
    "\n",
    "        utils.plot_strokes(ax[i][-1], utils.to_normal_strokes(d2))\n",
    "        ax[i][-1].set(xlabel=idx2)\n",
    "        \n",
    "fig.suptitle(\"Interpolation Between Samples\")\n",
    "\n",
    "utils.plt_show(rect=[0, 0, 1, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Perplexities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate perplexity using the method from [here](http://colinmorris.github.io/blog/bad_flamingos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n = len(ds_test)\n",
    "\n",
    "ppxs = np.zeros(n)\n",
    "\n",
    "for i in trange(n // batch_size + 1):\n",
    "    batch = ds_test[i*batch_size:(i+1)*batch_size]\n",
    "    seq_lens = np.argmax(batch[:,:,4]==1,-1)\n",
    "    \n",
    "    enc_in, dec_in = batch[:,1:], batch[:,:-1]\n",
    "    outputs = sketchrnn.models['full']([enc_in, dec_in])[0]\n",
    "    loss = models.calculate_md_loss(enc_in, outputs)\n",
    "    \n",
    "    ppxs[i*batch_size:(i+1)*batch_size] = tf.math.reduce_sum(tf.squeeze(loss),-1) / seq_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = mpl.colors.Normalize(vmin=ppxs.min(), vmax=ppxs.max())\n",
    "cmap = mpl.cm.get_cmap('RdYlBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "ax[0].plot(n_strokes - (np.random.rand(len(n_strokes)) - .5), ppxs, 'bo',alpha=0.3)\n",
    "ax[0].set(xlabel=\"strokes\", ylabel=\"perplexity\",\n",
    "          title=\"perplexity vs strokes\")\n",
    "\n",
    "ax[1].plot(n_points - (np.random.rand(len(n_points)) - .5), ppxs, 'bo',alpha=0.3)\n",
    "ax[1].set(xlabel=\"points\", ylabel=\"perplexity\",\n",
    "          title=\"perplexity vs points\")\n",
    "\n",
    "utils.plt_show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the best samples with best scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = [4, 10]\n",
    "\n",
    "fig, ax = plt.subplots(n[0],n[1],figsize=(12, 5))\n",
    "\n",
    "perm = np.argsort(ppxs)[:n[0]*n[1]]\n",
    "\n",
    "for i, idx in enumerate(perm):\n",
    "    x, y = i // n[1], i % n[1]\n",
    "    utils.plot_strokes(ax[x][y], utils.to_normal_strokes(ds_test[idx]), ec=cmap(norm(ppxs[idx])))\n",
    "    ax[x][y].set(xlabel='{}\\n({:.4f})'.format(idx, ppxs[idx]))\n",
    "    \n",
    "fig.suptitle(\"Best Samples\")\n",
    "    \n",
    "utils.plt_show(rect=[0, 0, 1, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the worst ones..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = [4, 10]\n",
    "\n",
    "fig, ax = plt.subplots(n[0],n[1],figsize=(12, 5))\n",
    "\n",
    "perm = np.argsort(ppxs)[-n[0]*n[1]:][::-1]\n",
    "\n",
    "for i, idx in enumerate(perm):\n",
    "    x, y = i // n[1], i % n[1]\n",
    "    utils.plot_strokes(ax[x][y], utils.to_normal_strokes(ds_test[idx]), ec=cmap(norm(ppxs[idx])))\n",
    "    ax[x][y].set(xlabel='{}\\n({:.4f})'.format(idx,ppxs[idx]))\n",
    "    \n",
    "fig.suptitle(\"Worst Samples\")\n",
    "    \n",
    "utils.plt_show(rect=[0, 0, 1, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Layout with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use TSNE, but since essentially the latent space is gaussian, PCA should be enough here. Read more [here](https://www.cs.toronto.edu/~hinton/csc2515/notes/lec7middle.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = sketchrnn.models['encoder'].predict(ds_test[:,1:])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2, svd_solver='randomized', whiten=True).fit(Z)\n",
    "print(\"Explained variances ratio: {}\".format(pca.explained_variance_ratio_))\n",
    "print(\"Explained variances: {}\".format(pca.explained_variance_))\n",
    "\n",
    "Z_pca = pca.transform(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((pc1_min, pc2_min), (pc1_max, pc2_max)) = np.percentile(Z_pca, q=[1, 99], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "\n",
    "sc = ax.scatter(*Z_pca.T, c=ppxs, alpha=0.5,cmap=cmap)\n",
    "ax.set(xlabel='$pc_1$',ylabel='$pc_2$',\n",
    "       xlim=(pc1_min,pc1_max),ylim=(pc2_min,pc2_max))\n",
    "\n",
    "cbar = plt.colorbar(sc)\n",
    "cbar.ax.set_ylabel('perplexity')\n",
    "\n",
    "utils.plt_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "for i, strokes in enumerate(ds_test):\n",
    "    t = norm(ppxs[i])\n",
    "    path = utils.make_mpl_path(utils.to_normal_strokes(strokes))\n",
    "    path.vertices *= 0.05 + (1-t) * 0.05\n",
    "    path.vertices += Z_pca[i]\n",
    "    ax.add_patch(PathPatch(path, lw=max(1-t,0.4), fc='none',\n",
    "                           ec=cmap(t), alpha=max(1-t,0.3)))\n",
    "    \n",
    "ax.set(xlim=(pc1_min,pc1_max),ylim=(pc2_min,pc2_max),\n",
    "       xlabel='$pc_1$',ylabel='$pc_2$',\n",
    "       title=\"PCA Layout of Latent Vectors\")\n",
    "\n",
    "utils.plt_show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick some of the best samples and interpolate between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "indices = shuffle(np.argsort(ppxs)[:50])[:n]\n",
    "\n",
    "ds = ds_test[indices]\n",
    "zs = sketchrnn.models['encoder'].predict(ds[:,1:])[0]\n",
    "\n",
    "fig, ax = plt.subplots(n, 13, figsize=(12, 5))\n",
    "\n",
    "with tqdm(total=n * 11) as pbar:\n",
    "    it = range(n)\n",
    "    for s, t in zip(it, np.roll(it,-1)):\n",
    "        d1, d2 = ds[s], ds[t]\n",
    "        z1, z2 = zs[s], zs[t]\n",
    "\n",
    "        utils.plot_strokes(ax[s][0], utils.to_normal_strokes(d1))\n",
    "        ax[s][0].set(xlabel=indices[s])\n",
    "        \n",
    "        for j in range(11):\n",
    "            z = np.expand_dims(utils.slerp(z1,z2,j*0.1),0)\n",
    "            strokes = sketchrnn.sample(z=z, greedy=True)\n",
    "            utils.plot_strokes(ax[s][j+1], utils.to_normal_strokes(strokes))\n",
    "            ax[s][j+1].set(xlabel='$t={:.1f}$'.format(j*0.1))\n",
    "            pbar.update(1)\n",
    "\n",
    "        utils.plot_strokes(ax[s][-1], utils.to_normal_strokes(d2))\n",
    "        ax[s][-1].set(xlabel=indices[t])\n",
    "        \n",
    "utils.plt_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_per_inter = 60\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,3))\n",
    "\n",
    "z = sketchrnn.sample(z=zs[np.newaxis,0], greedy=True)\n",
    "patch = utils.plot_strokes(ax, utils.to_normal_strokes(strokes))\n",
    "path = patch.get_path()\n",
    "\n",
    "def animate(strokes):\n",
    "    newPath = utils.make_mpl_path(utils.to_normal_strokes(strokes))\n",
    "    path.vertices, path.codes = newPath.vertices, newPath.codes\n",
    "    return [patch]\n",
    "\n",
    "def frames(n):\n",
    "    nz = len(zs)\n",
    "    for i, (z1, z2) in enumerate(zip(zs,np.roll(zs,-1,0))):\n",
    "        for t in np.linspace(0,1,n):\n",
    "            utils.update_progress((i+t)/nz)\n",
    "            z = np.expand_dims(utils.slerp(z1, z2, t), 0)\n",
    "            strokes = sketchrnn.sample(z=z, greedy=True)\n",
    "            yield strokes\n",
    "\n",
    "anim = FuncAnimation(fig, animate, frames=frames(frames_per_inter), \n",
    "                     interval=30, save_count=len(zs)*frames_per_inter, blit=True)\n",
    "plt.close(anim._fig)\n",
    "anim.save('../assets/rabbits_loop.gif', writer='pillow', fps=30)\n",
    "\n",
    "# HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RabbitsLoop](../assets/rabbits_1692_144.gif \"segment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow GPU 2.6 (py39)",
   "language": "python",
   "name": "tensorflow-gpu-2.6-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
